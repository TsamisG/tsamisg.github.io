<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MNIST Dataset - Convolutional Neural Networks in PyTorch</title>
	<meta property="og:image" content="https://avatars.githubusercontent.com/u/9919?s=200&v=4">
    <link rel="icon" href="https://cdn-icons-png.flaticon.com/512/25/25231.png" type="image/png" sizes="16x16 32x32 64x64">
    <link rel="stylesheet" href="/styles.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400&display=swap">
    <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css'>  
	<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
    <div id="container">
        <div id="sidebar">

            <div id="sidebar-content">
                <ul style="list-style-type: none;">
                    <li><a href="/index.html">Home</a></li>
                    <li><a href="/projects.html">Projects</a></li>
                    <li><a href="/info.html">About Me</a></li>
                    <li><a href="/contact.html">Contact</a></li>
                </ul>
            </div>

            <div id="sidebar-contact-icons">
                <a href="https://www.linkedin.com/in/georgios-tsamis-799992212/">
                    <i class='fa fa-linkedin-square' style="font-size:2em; margin-right:1em;"></i>
                </a>

                <a href="https://github.com/TsamisG">
                    <i class='fa fa-github' style="font-size:2em; margin-right:1em;"></i>
                </a>

                <a href="mailto:tsamis.g@outlook.com">
                    <i class='fa fa-envelope-square' style="font-size:2em;"></i>
                </a>

                
            </div>
            
        </div>

		<div id="content">
			<h1>MNIST Dataset - Convolutional Neural Networks in PyTorch</h1>
				<p>In this project, a Convolutional Neural Network model is trained on the MNIST dataset.
					The MNIST dataset contains small images of handwritten digits. It includes 60,000 training and
					10,000 testing examples; each example being a 28x28 grayscale image. The images have been
					size-normalized and centered. This makes it	a very easy dataset to work with, as minimum
					pre-processing is needed.<br />
					In this sense, in this project, a classification model is trained to
					identify and correctly classify handwritten digits. To build the model, the PyTorch's python
					library is utilized.<br />
					See more: <a href="http://yann.lecun.com/exdb/mnist/">"The MNIST Database"</a>
					
				</p>

			<br />
			<hr>
			<br />

            <h2>Project Overview</h2>
                <p>
                    The aim of this project is to effectively train a Convolutional Neural Network model to recognize
                    and correctly classify images of handwritten digits. Convolutional Neural Networks, or CNNs for short,
                    have proven their ability to extract features from images and model the mapping between an
                    image's features and the corresponding label. For the CNN's implementation in this project, the
                    PyTorch library is used. To provide a more accurate and reliable estimate of the model's performance,
                    the K-Fold Cross Validation method is implemented
                    in the model's training stage. After the model is trained, it is tested using the test set to
                    evaluate its performance.
                </p>

            <br />
            <hr>
            <br />

            <h2>Project Outline</h2>
                <p>
                    The project is divided into the following sections:
                    <ul>
                        <li>The Model</li>
                        <li>Training the Model</li>
                        <li>Testing the Model</li>
                    </ul>
                </p>
            <br />
            <hr>
            <br />

            <h2>The Model</h2>
                <p>
                    The implemented model's architecture is presented:
                    <ul>
                        <li>Convolutional Layer with 32 channels, kernel size of 3 pixels, and stride equal to 1.</li>
                        <li>MaxPooling Layer with kernel size of 2 pixels, and stride equal to 2.</li>
                        <li>Fully Connected Layer with 256 Neurons.</li>
                        <lI>Fully Connected Layer with 10 Neurons (Output Layer).</lI>
                    </ul>
                    The selected activation function for each hidden layer is the ReLU, while the softmax function is selected
                    for the output layer. The selected loss function is the Cross Entropy
                    Loss, and the selected optimizer is Adam.<br />

                    In order to provide a more accurate and reliable estimate of the model's performance,
                    the K-Fold Cross Validation method is implemented. K-Fold Cross
                    Validation devides the training dataset into K batches or folds. At each epoch,
                    the model is trained K times, each time using a different fold for validation and the
                    remaining folds for training, providing a more reliable estimate of its generalization performance.<br />
                    The model is created as a python object, which inherits the characteristics of the nn.Module class from
                    PyTorch. In the __init__ method, the model's hyperparameters are declared. To calculate the input
                    dimensions of the first fully connected layer, the calculate_fc_input_dims method is used, which is
                    presented below.
                </p>
<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">class</span> <span style="color: #BB0066; font-weight: bold">CNN_Classification_Model</span>(nn<span style="color: #333333">.</span>Module):
    <span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">__init__</span>(<span style="color: #007020">self</span>, input_dims, num_classes, learning_rate<span style="color: #333333">=</span><span style="color: #6600EE; font-weight: bold">1e-04</span>):
        <span style="color: #007020">super</span>(CNN_Classification_Model, <span style="color: #007020">self</span>)<span style="color: #333333">.</span>__init__()

        <span style="color: #007020">self</span><span style="color: #333333">.</span>input_dims <span style="color: #333333">=</span> input_dims
        <span style="color: #007020">self</span><span style="color: #333333">.</span>n_classes <span style="color: #333333">=</span> n_classes
        
        <span style="color: #007020">self</span><span style="color: #333333">.</span>conv <span style="color: #333333">=</span> nn<span style="color: #333333">.</span>Conv2d(input_dims[<span style="color: #0000DD; font-weight: bold">0</span>], <span style="color: #0000DD; font-weight: bold">32</span>, kernel_size<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">3</span>, stride<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">1</span>)
        <span style="color: #007020">self</span><span style="color: #333333">.</span>pool <span style="color: #333333">=</span> nn<span style="color: #333333">.</span>MaxPool2d(<span style="color: #0000DD; font-weight: bold">2</span>, <span style="color: #0000DD; font-weight: bold">2</span>)

        fc_input_dims <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>calculate_fc_input_dims()

        <span style="color: #007020">self</span><span style="color: #333333">.</span>fc1 <span style="color: #333333">=</span> nn<span style="color: #333333">.</span>Linear(fc_input_dims, <span style="color: #0000DD; font-weight: bold">256</span>)
        <span style="color: #007020">self</span><span style="color: #333333">.</span>fc2 <span style="color: #333333">=</span> nn<span style="color: #333333">.</span>Linear(<span style="color: #0000DD; font-weight: bold">256</span>, n_classes)

        <span style="color: #007020">self</span><span style="color: #333333">.</span>loss <span style="color: #333333">=</span> nn<span style="color: #333333">.</span>CrossEntropyLoss()
        <span style="color: #007020">self</span><span style="color: #333333">.</span>optimizer <span style="color: #333333">=</span> optim<span style="color: #333333">.</span>Adam(<span style="color: #007020">self</span><span style="color: #333333">.</span>parameters(), lr<span style="color: #333333">=</span>learning_rate)
</pre></div>
                <p>
                    The forward method implements the forward-pass of the input image.
                </p>

<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">    <span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">forward</span>(<span style="color: #007020">self</span>, X):
        conv <span style="color: #333333">=</span> F<span style="color: #333333">.</span>relu(<span style="color: #007020">self</span><span style="color: #333333">.</span>conv(X))
        pool <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>pool(conv)
        fc_input <span style="color: #333333">=</span> pool<span style="color: #333333">.</span>view(pool<span style="color: #333333">.</span>shape[<span style="color: #0000DD; font-weight: bold">0</span>], <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">1</span>)
        fc1 <span style="color: #333333">=</span> F<span style="color: #333333">.</span>relu(<span style="color: #007020">self</span><span style="color: #333333">.</span>fc1(fc_input))
        fc2 <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>fc2(fc1)
        <span style="color: #008800; font-weight: bold">return</span> F<span style="color: #333333">.</span>softmax(fc2, dim<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">1</span>)
    </pre></div>
                
                <p>
                    The calculate_fc_input_dims method is in fact a dummy forward-pass of a blank image from the convolutional
                    and max pooling layer. This dummy forward-pass output is then reshaped to a one-dimensional array, which
                    length is the dimension of the fully connected layer's input.
                    
                </p>
<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">    <span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">calculate_fc_input_dims</span>(<span style="color: #007020">self</span>):
        x <span style="color: #333333">=</span> T<span style="color: #333333">.</span>zeros((<span style="color: #0000DD; font-weight: bold">1</span>,) <span style="color: #333333">+</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>input_dims)
        x <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>conv(x)
        x <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>pool(x)
        x <span style="color: #333333">=</span> x<span style="color: #333333">.</span>view(x<span style="color: #333333">.</span>shape[<span style="color: #0000DD; font-weight: bold">0</span>], <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">1</span>)
        <span style="color: #008800; font-weight: bold">return</span> x<span style="color: #333333">.</span>shape[<span style="color: #0000DD; font-weight: bold">1</span>]
    </pre></div>

                <p>
                    The fit method is the most complicated one. Given the input data X and the output labels Y of the dataset,
                    it implements a trick using the batches indices to select the validation fold for each iteration. The
                    validation fold's index is incremented by one at each iteration and is reset after it reaches the maximum.
                    The fit method returns the training and validation losses per epoch.
                </p>

<!-- HTML generated using hilite.me --><div style="background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">    <span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">fit</span>(<span style="color: #007020">self</span>, X, Y, epochs<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">1000</span>, print_every<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>, batch_size<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">256</span>):
        
        n_batches <span style="color: #333333">=</span> <span style="color: #007020">int</span>(np<span style="color: #333333">.</span>ceil(X<span style="color: #333333">.</span>shape[<span style="color: #0000DD; font-weight: bold">0</span>]<span style="color: #333333">/</span>batch_size))
        val_idx <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>
        
        train_loss_per_epoch <span style="color: #333333">=</span> []
        val_loss_per_epoch <span style="color: #333333">=</span> []
        
        <span style="color: #008800; font-weight: bold">for</span> epoch <span style="color: #000000; font-weight: bold">in</span> <span style="color: #007020">range</span>(epochs):
            
            batch_train_loss <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>
            
            batch_indices <span style="color: #333333">=</span> [n <span style="color: #008800; font-weight: bold">for</span> n <span style="color: #000000; font-weight: bold">in</span> <span style="color: #007020">range</span>(n_batches)]
            batch_indices<span style="color: #333333">.</span>pop(val_idx)
            
            <span style="color: #008800; font-weight: bold">for</span> i <span style="color: #000000; font-weight: bold">in</span> batch_indices:
                Xbatch_train <span style="color: #333333">=</span> X[i<span style="color: #333333">*</span>batch_size:(i<span style="color: #333333">+</span><span style="color: #0000DD; font-weight: bold">1</span>)<span style="color: #333333">*</span>batch_size]
                Ybatch_train <span style="color: #333333">=</span> Y[i<span style="color: #333333">*</span>batch_size:(i<span style="color: #333333">+</span><span style="color: #0000DD; font-weight: bold">1</span>)<span style="color: #333333">*</span>batch_size]
            
                <span style="color: #007020">self</span><span style="color: #333333">.</span>optimizer<span style="color: #333333">.</span>zero_grad()
                Yhat_train <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>forward(Xbatch_train)
                loss <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>loss(Yhat_train, Ybatch_train)
                batch_train_loss <span style="color: #333333">+=</span> loss<span style="color: #333333">.</span>item()
                
                loss<span style="color: #333333">.</span>backward()
                <span style="color: #007020">self</span><span style="color: #333333">.</span>optimizer<span style="color: #333333">.</span>step()
            
            batch_train_loss <span style="color: #333333">/=</span> n_batches
            
            Xbatch_val <span style="color: #333333">=</span> X[val_idx<span style="color: #333333">*</span>batch_size:(val_idx<span style="color: #333333">+</span><span style="color: #0000DD; font-weight: bold">1</span>)<span style="color: #333333">*</span>batch_size]
            Ybatch_val <span style="color: #333333">=</span> Y[val_idx<span style="color: #333333">*</span>batch_size:(val_idx<span style="color: #333333">+</span><span style="color: #0000DD; font-weight: bold">1</span>)<span style="color: #333333">*</span>batch_size]
            Yhat_val <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>forward(Xbatch_val)<span style="color: #333333">.</span>detach()
            batch_val_loss <span style="color: #333333">=</span> <span style="color: #007020">self</span><span style="color: #333333">.</span>loss(Yhat_val, Ybatch_val)<span style="color: #333333">.</span>detach()<span style="color: #333333">.</span>item()

            val_idx <span style="color: #333333">=</span> (val_idx <span style="color: #333333">+</span> <span style="color: #0000DD; font-weight: bold">1</span>) <span style="color: #333333">%</span> n_batches
            
            train_loss_per_epoch<span style="color: #333333">.</span>append(batch_train_loss)
            val_loss_per_epoch<span style="color: #333333">.</span>append(batch_val_loss)
            
            <span style="color: #008800; font-weight: bold">if</span> epoch <span style="color: #333333">==</span> <span style="color: #0000DD; font-weight: bold">0</span> <span style="color: #000000; font-weight: bold">or</span> (epoch<span style="color: #333333">+</span><span style="color: #0000DD; font-weight: bold">1</span>) <span style="color: #333333">%</span> print_every <span style="color: #333333">==</span> <span style="color: #0000DD; font-weight: bold">0</span>:
                <span style="color: #008800; font-weight: bold">print</span>(f<span style="background-color: #fff0f0">&#39;[ Epoch: {epoch+1} / {epochs} | Training Loss: {batch_train_loss:.3f}] | Validation Loss: {batch_val_loss:.3f}&#39;</span>)

        <span style="color: #008800; font-weight: bold">return</span> train_loss_per_epoch, val_loss_per_epoch
</pre></div>

            

            <br />
            <hr>
            <br />

            <h2>Training the Model</h2>
                <p>
                    To train the model, the data has to be imported. The MNIST dataset is stored in a csv; each row
                    representing an image and each element of each row a pixel value ranging from 0 to 255. Thus,
                    each row is reshaped to a 28x28 image and its values are min-max normalized by dividing by 255.
                    After the model is instantiated, the fit method is called to train the model. The loss per epoch
                    for both training and validation is shown in Figure 1 below. The model is trained for 200 epochs
                    and the losses converge with no sign of overfitting.
                </p>
                <figure>
                    <img src="/images/mnistCNN/training_convergence.png">
                    <figcaption>Fig. 1 - The model's training convergence.</figcaption>
                </figure>
            <br />
            <hr>
            <br />

            <h2>Testing the Model</h2>
                <p>
                    To test the model, the testing data has to be imported and preprocessed in the same way as
                    the training dataset. As the dataset consists of 10'000 examples, the data is forwarded through the
                    model in batches to reduce the RAM requirements of the task. Then, by comparing the model's
                    predictions with the ground truth, the classification rate is calculated. The model performs
                    very good, with 98.31% classification rate.
                </p>
            <br />
            <hr>
            <br />

            <h2>Jupyter Notebook</h2>
                <p>
                    The notebook created for this project is provided below, but can also be found in my Github repository
                    <a href="https://github.com/TsamisG/MNIST_Model">MNIST_Model</a>. The training and testing dataset
                    can be found there too.
                </p>
                <div class="container" style="height: 100vh; width: 100%;">
					<iframe src="/images/mnistCNN/MNIST_Model.html"
					style="height: 100%; width: 300%;"></iframe>
				</div>

            
            <br />
            <hr>
            <br />
            <h2>References</h2>
                <p>Aggarwal, C. C. (2019). Neural Networks and Deep Learning: A Textbook (1st ed.). Springer Cham.</p>
                <p>Kuhn, M., & Johnson, K. (2013). Applied Predictive Modeling. Springer.</p>
                <p>Goodfellow, I., Bengio, Y., Courville, A., & Bengio, Y. (2016). Deep Learning (Vol. 1). MIT Press Cambridge.</p>
                <p>Liu, L., Wu, Y., Wei, W., Cao, W., Sahin, S., & Zhang, Q. (2018). Benchmarking Deep Learning Frameworks:
                    Design Considerations, Metrics and Beyond. 2018 IEEE 38th International Conference on
                    Distributed Computing Systems (ICDCS), 1258-1269. [doi:10.1109/ICDCS.2018.00125].</p>
                <p>Wu, Y., Liu, L., Pu, C., Cao, W., Sahin, S., Wei, W., & Zhang, Q. (2019). A Comparative Measurement Study of Deep Learning as a Service Framework. IEEE Transactions on Services Computing, 1-1. [doi:10.1109/TSC.2019.2928551]</p>
                <p>Wu, Y., Cao, W., Sahin, S., & Liu, L. (2018). Experimental Characterizations and Analysis of Deep Learning Frameworks. 2018 IEEE 38th International Conference on Big Data, December.</p>
                <p>Pytorch Documentation (<a href="https://pytorch.org/docs/stable/index.html">https://pytorch.org/docs/stable/index.html</a>)</p>
                
            
            <br />
            <hr>
            <br />


            <a href="/projects.html" class="button">Back to Projects</a>
            <br />
            <br />
	
	</div>

	</body>
</html>