<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LunarLander - Learning with Monte-Carlo Policy Gradient</title>
	<meta property="og:image" content="https://avatars.githubusercontent.com/u/9919?s=200&v=4">
	<link rel="icon" href="https://cdn-icons-png.flaticon.com/512/25/25231.png" type="image/png" sizes="16x16 32x32 64x64">
    <link rel="stylesheet" href="/styles.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=PT+Serif:wght@400&display=swap">
    <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css'>  
	<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
<body>
    <div id="container">
        <div id="sidebar">

            <div id="sidebar-content">
                <ul style="list-style-type: none;">
                    <li><a href="/index.html">Home</a></li>
                    <li><a href="/projects.html">Projects</a></li>
                    <li><a href="/info.html">About Me</a></li>
                    <li><a href="/contact.html">Contact</a></li>
                </ul>
            </div>

            <div id="sidebar-contact-icons">
                <a href="https://www.linkedin.com/in/georgios-tsamis-799992212/">
                    <i class='fa fa-linkedin-square' style="font-size:2em; margin-right:1em;"></i>
                </a>

                <a href="https://github.com/TsamisG">
                    <i class='fa fa-github' style="font-size:2em; margin-right:1em;"></i>
                </a>

                <a href="mailto:tsamis.g@outlook.com">
                    <i class='fa fa-envelope-square' style="font-size:2em;"></i>
                </a>

                
            </div>
            
        </div>

		<div id="content">

			<h1>LunarLander - Learning with Monte-Carlo Policy Gradient</h1>

				<p>In this mini-project, the OpenAI's Lunar Lander Gym environment is solved using
					a Neural Network to represent the agent's policy.
					The Q-Learning algorithm is used in an episodic Monte-Carlo fashion in order to train the Agent.</p>
				<p> This OpenAI's Gym environment is a classic rocket trajectory optimization problem.
					According to Pontryagin's maximum principle, it is optimal to fire the engine at full throttle or
					turn it off. This is the reason why this environment has discrete actions: engine on or off. The
					goal is to safely land the vehicle on the surface using four discrete actions at each step:
					do nothing, fire left orientation engine, fire main engine, fire right orientation engine. The
					landing pad is always at coordinates (0,0). Landing outside of the landing pad is possible.
					The lander's fuel is infinite.<br />
					See more: 
					<a href="https://www.gymlibrary.dev/environments/box2d/lunar_lander/"> Lunar Lander - Gym Documentation</a></p>
			
			<br />
			<hr>
			<br />
			<h2>Under Construction!</h2>

			<br />
			<hr>
			<br />


			<a href="/projects.html" class="button">Back to Projects</a>
			<br />
			<br />

	</div>

	</body>
</html>